{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Traceback (most recent call last):\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n                         ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 15, in swig_import_helper\n    import imp\nModuleNotFoundError: No module named 'imp'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\__init__.py:66\u001b[0m\n\u001b[0;32m     63\u001b[0m   \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     64\u001b[0m     \u001b[38;5;66;03m# TODO(keveman,mrry): Support dynamic op loading on platforms that do not\u001b[39;00m\n\u001b[0;32m     65\u001b[0m     \u001b[38;5;66;03m# use `dlopen()` for dynamic loading.\u001b[39;00m\n\u001b[1;32m---> 66\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m pywrap_tensorflow\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:28\u001b[0m\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m _mod\n\u001b[1;32m---> 28\u001b[0m _pywrap_tensorflow \u001b[38;5;241m=\u001b[39m \u001b[43mswig_import_helper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m swig_import_helper\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py:15\u001b[0m, in \u001b[0;36mswig_import_helper\u001b[1;34m()\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpath\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m dirname\n\u001b[1;32m---> 15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mimp\u001b[39;00m\n\u001b[0;32m     16\u001b[0m fp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'imp'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mtf\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodels\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Sequential\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeras\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlayers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Dense\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\__init__.py:24\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m__future__\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m print_function\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# pylint: disable=wildcard-import\u001b[39;00m\n\u001b[1;32m---> 24\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpython\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[0;32m     25\u001b[0m \u001b[38;5;66;03m# pylint: enable=wildcard-import\u001b[39;00m\n\u001b[0;32m     26\u001b[0m \n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Lazily import the `tf.contrib` module. This avoids loading all of the\u001b[39;00m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# dependencies of `tf.contrib` at `import tensorflow` time.\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01m_LazyContribLoader\u001b[39;00m(\u001b[38;5;28mobject\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\__init__.py:72\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m:\n\u001b[0;32m     68\u001b[0m   msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mFailed to load the native TensorFlow runtime.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;124mSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;124mfor some common reasons and solutions.  Include the entire stack trace\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;124mabove this error message when asking for help.\u001b[39m\u001b[38;5;124m\"\"\"\u001b[39m \u001b[38;5;241m%\u001b[39m traceback\u001b[38;5;241m.\u001b[39mformat_exc()\n\u001b[1;32m---> 72\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(msg)\n\u001b[0;32m     74\u001b[0m \u001b[38;5;66;03m# Protocol buffers\u001b[39;00m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtensorflow\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mframework\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mgraph_pb2\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n",
      "\u001b[1;31mImportError\u001b[0m: Traceback (most recent call last):\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\__init__.py\", line 66, in <module>\n    from tensorflow.python import pywrap_tensorflow\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 28, in <module>\n    _pywrap_tensorflow = swig_import_helper()\n                         ^^^^^^^^^^^^^^^^^^^^\n  File \"c:\\Users\\Admin\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tensorflow\\python\\pywrap_tensorflow.py\", line 15, in swig_import_helper\n    import imp\nModuleNotFoundError: No module named 'imp'\n\n\nFailed to load the native TensorFlow runtime.\n\nSee https://github.com/tensorflow/tensorflow/blob/master/tensorflow/g3doc/get_started/os_setup.md#import_error\n\nfor some common reasons and solutions.  Include the entire stack trace\nabove this error message when asking for help."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 569 entries, 0 to 568\n",
      "Data columns (total 30 columns):\n",
      " #   Column                   Non-Null Count  Dtype  \n",
      "---  ------                   --------------  -----  \n",
      " 0   radius_mean              569 non-null    float64\n",
      " 1   texture_mean             569 non-null    float64\n",
      " 2   perimeter_mean           569 non-null    float64\n",
      " 3   area_mean                569 non-null    float64\n",
      " 4   smoothness_mean          569 non-null    float64\n",
      " 5   compactness_mean         569 non-null    float64\n",
      " 6   concavity_mean           569 non-null    float64\n",
      " 7   concave points_mean      569 non-null    float64\n",
      " 8   symmetry_mean            569 non-null    float64\n",
      " 9   fractal_dimension_mean   569 non-null    float64\n",
      " 10  radius_se                569 non-null    float64\n",
      " 11  texture_se               569 non-null    float64\n",
      " 12  perimeter_se             569 non-null    float64\n",
      " 13  area_se                  569 non-null    float64\n",
      " 14  smoothness_se            569 non-null    float64\n",
      " 15  compactness_se           569 non-null    float64\n",
      " 16  concavity_se             569 non-null    float64\n",
      " 17  concave points_se        569 non-null    float64\n",
      " 18  symmetry_se              569 non-null    float64\n",
      " 19  fractal_dimension_se     569 non-null    float64\n",
      " 20  radius_worst             569 non-null    float64\n",
      " 21  texture_worst            569 non-null    float64\n",
      " 22  perimeter_worst          569 non-null    float64\n",
      " 23  area_worst               569 non-null    float64\n",
      " 24  smoothness_worst         569 non-null    float64\n",
      " 25  compactness_worst        569 non-null    float64\n",
      " 26  concavity_worst          569 non-null    float64\n",
      " 27  concave points_worst     569 non-null    float64\n",
      " 28  symmetry_worst           569 non-null    float64\n",
      " 29  fractal_dimension_worst  569 non-null    float64\n",
      "dtypes: float64(30)\n",
      "memory usage: 133.5 KB\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv(\"breast-cancer.csv\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'] = df['diagnosis'].map({'M': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['diagnosis','id'],axis=1)\n",
    "y=df['diagnosis']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "12/12 [==============================] - 0s 10ms/step - loss: 9.2372 - accuracy: 0.4258 - val_loss: 7.5427 - val_accuracy: 0.3626\n",
      "Epoch 2/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 2.2910 - accuracy: 0.6401 - val_loss: 1.4196 - val_accuracy: 0.7143\n",
      "Epoch 3/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9846 - accuracy: 0.8379 - val_loss: 1.3798 - val_accuracy: 0.6703\n",
      "Epoch 4/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 1.0537 - accuracy: 0.8544 - val_loss: 1.1424 - val_accuracy: 0.7253\n",
      "Epoch 5/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.8011 - accuracy: 0.8709 - val_loss: 0.6856 - val_accuracy: 0.8022\n",
      "Epoch 6/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.6339 - accuracy: 0.8571 - val_loss: 0.6680 - val_accuracy: 0.8791\n",
      "Epoch 7/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5889 - accuracy: 0.8819 - val_loss: 0.7260 - val_accuracy: 0.8791\n",
      "Epoch 8/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4153 - accuracy: 0.8984 - val_loss: 0.4230 - val_accuracy: 0.9011\n",
      "Epoch 9/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3459 - accuracy: 0.9093 - val_loss: 0.3735 - val_accuracy: 0.9011\n",
      "Epoch 10/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3458 - accuracy: 0.9121 - val_loss: 0.3444 - val_accuracy: 0.8901\n",
      "Epoch 11/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3989 - accuracy: 0.8709 - val_loss: 0.5534 - val_accuracy: 0.8571\n",
      "Epoch 12/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2992 - accuracy: 0.8984 - val_loss: 0.3630 - val_accuracy: 0.8901\n",
      "Epoch 13/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3023 - accuracy: 0.9038 - val_loss: 0.3283 - val_accuracy: 0.9011\n",
      "Epoch 14/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3245 - accuracy: 0.8929 - val_loss: 0.2958 - val_accuracy: 0.9011\n",
      "Epoch 15/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2846 - accuracy: 0.9011 - val_loss: 0.3315 - val_accuracy: 0.9011\n",
      "Epoch 16/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3221 - accuracy: 0.8791 - val_loss: 0.5367 - val_accuracy: 0.8571\n",
      "Epoch 17/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3597 - accuracy: 0.8956 - val_loss: 0.3011 - val_accuracy: 0.8901\n",
      "Epoch 18/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.8929 - val_loss: 0.3857 - val_accuracy: 0.8571\n",
      "Epoch 19/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.9038 - val_loss: 0.2513 - val_accuracy: 0.9011\n",
      "Epoch 20/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3671 - accuracy: 0.8681 - val_loss: 0.3014 - val_accuracy: 0.8681\n",
      "Epoch 21/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3148 - accuracy: 0.8846 - val_loss: 0.5882 - val_accuracy: 0.8352\n",
      "Epoch 22/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8984 - val_loss: 0.3466 - val_accuracy: 0.8462\n",
      "Epoch 23/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4679 - accuracy: 0.8352 - val_loss: 0.3757 - val_accuracy: 0.8681\n",
      "Epoch 24/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8956 - val_loss: 0.6299 - val_accuracy: 0.8352\n",
      "Epoch 25/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3182 - accuracy: 0.8984 - val_loss: 0.2757 - val_accuracy: 0.9121\n",
      "Epoch 26/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4348 - accuracy: 0.8654 - val_loss: 2.6792 - val_accuracy: 0.4725\n",
      "Epoch 27/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.9672 - accuracy: 0.7885 - val_loss: 0.5692 - val_accuracy: 0.8901\n",
      "Epoch 28/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5130 - accuracy: 0.8901 - val_loss: 0.9090 - val_accuracy: 0.7473\n",
      "Epoch 29/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.4579 - accuracy: 0.8681 - val_loss: 1.1556 - val_accuracy: 0.8242\n",
      "Epoch 30/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.5059 - accuracy: 0.8764 - val_loss: 0.3326 - val_accuracy: 0.8681\n",
      "Epoch 31/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4980 - accuracy: 0.8626 - val_loss: 0.4644 - val_accuracy: 0.8901\n",
      "Epoch 32/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2910 - accuracy: 0.9066 - val_loss: 0.3296 - val_accuracy: 0.9121\n",
      "Epoch 33/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2303 - accuracy: 0.9231 - val_loss: 0.3415 - val_accuracy: 0.9121\n",
      "Epoch 34/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3888 - accuracy: 0.9011 - val_loss: 0.9306 - val_accuracy: 0.7143\n",
      "Epoch 35/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.4290 - accuracy: 0.8819 - val_loss: 0.3762 - val_accuracy: 0.9011\n",
      "Epoch 36/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.9011 - val_loss: 0.2488 - val_accuracy: 0.9121\n",
      "Epoch 37/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3346 - accuracy: 0.8791 - val_loss: 0.3814 - val_accuracy: 0.9011\n",
      "Epoch 38/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2342 - accuracy: 0.9203 - val_loss: 0.2226 - val_accuracy: 0.9011\n",
      "Epoch 39/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.9011 - val_loss: 0.2334 - val_accuracy: 0.9231\n",
      "Epoch 40/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.3666 - accuracy: 0.8901 - val_loss: 0.5421 - val_accuracy: 0.8462\n",
      "Epoch 41/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.9258 - val_loss: 0.3662 - val_accuracy: 0.8681\n",
      "Epoch 42/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2398 - accuracy: 0.9313 - val_loss: 0.2908 - val_accuracy: 0.9121\n",
      "Epoch 43/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.3247 - accuracy: 0.8846 - val_loss: 0.4037 - val_accuracy: 0.8901\n",
      "Epoch 44/50\n",
      "12/12 [==============================] - 0s 2ms/step - loss: 0.2429 - accuracy: 0.9121 - val_loss: 0.2068 - val_accuracy: 0.9121\n",
      "Epoch 45/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1923 - accuracy: 0.9258 - val_loss: 0.4174 - val_accuracy: 0.8571\n",
      "Epoch 46/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.2373 - accuracy: 0.9176 - val_loss: 0.3352 - val_accuracy: 0.9011\n",
      "Epoch 47/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1953 - accuracy: 0.9286 - val_loss: 0.1994 - val_accuracy: 0.9121\n",
      "Epoch 48/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1906 - accuracy: 0.9368 - val_loss: 0.1895 - val_accuracy: 0.9121\n",
      "Epoch 49/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1880 - accuracy: 0.9231 - val_loss: 0.2377 - val_accuracy: 0.9231\n",
      "Epoch 50/50\n",
      "12/12 [==============================] - 0s 3ms/step - loss: 0.1807 - accuracy: 0.9286 - val_loss: 0.1780 - val_accuracy: 0.9011\n",
      "4/4 [==============================] - 0s 5ms/step\n",
      "Test Accuracy: 0.956140350877193\n"
     ]
    }
   ],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Dense(units=128, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(units=32, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred_binary = np.round(y_pred).flatten()\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred_binary)\n",
    "print(f'Test Accuracy: {accuracy}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
